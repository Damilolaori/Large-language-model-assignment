{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8bc775a6c1f4c6d8b1618d58b7b154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_570320c4f336401fa438467fa8e81797",
              "IPY_MODEL_d3ca2f6697de470b83a071df0e959277",
              "IPY_MODEL_2a4294d57c18425c98449565f887062f"
            ],
            "layout": "IPY_MODEL_54219af59cea4e428fc3d418319e8dfd"
          }
        },
        "570320c4f336401fa438467fa8e81797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1780a0be35b4bcdbbaa389223cb23cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_276fe006f6de46a9802411340180b804",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        },
        "d3ca2f6697de470b83a071df0e959277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b883cc9a6134feb8e3ef42c5d323ed5",
            "max": 2471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b418204c51e646b3b4d769fa127f34ed",
            "value": 2471
          }
        },
        "2a4294d57c18425c98449565f887062f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea017bd4f3a400f939a4145b505885d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_55d273f081d64087850099f210abd1ff",
            "value": "â€‡6.33k/?â€‡[00:00&lt;00:00,â€‡134kB/s]"
          }
        },
        "54219af59cea4e428fc3d418319e8dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1780a0be35b4bcdbbaa389223cb23cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276fe006f6de46a9802411340180b804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b883cc9a6134feb8e3ef42c5d323ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b418204c51e646b3b4d769fa127f34ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bea017bd4f3a400f939a4145b505885d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d273f081d64087850099f210abd1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rLBv7aaWi8X6"
      },
      "outputs": [],
      "source": [
        "# Installing necessary packages\n",
        "!pip install transformers datasets tokenizers seqeval -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "KPNVcDYIlsNu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset from the Hugging Face datasets library\n",
        "conllpp = datasets.load_dataset(\"conllpp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej65EY4YqzoU",
        "outputId": "2e79dfec-d3bf-47e1-d051-0c33c4a25a46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the details of the dataset\n",
        "conllpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka_0T8gMhm5J",
        "outputId": "66c75a11-751f-498c-ceae-a396d8125b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing and displaying the first example from the training split of the dataset\n",
        "conllpp[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq1NUzzJiAjR",
        "outputId": "65a02190-b518-496a-9fcd-cdd9e6b2199e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing and displaying the features of the 'ner_tags' field from the training split\n",
        "conllpp[\"train\"].features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_aec-otjmsy",
        "outputId": "9388affd-4889-4516-b96c-4c3aac76e6a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a BERT tokenizer using the bert-base-uncased pre-trained model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "afyyUdXxkJWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b2419e-4b19-4cd4-ccb7-7009a082fa63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the first example from the training split of the 'conllpp' dataset and storing it in the 'text' variable\n",
        "text = conllpp[\"train\"][0]\n",
        "\n",
        "# Tokenize the 'tokens' field of the 'text' example using the BERT tokenizer\n",
        "tokenized_input = tokenizer(text['tokens'], is_split_into_words=True)\n",
        "# Converting the token IDs in the 'input_ids' field of the 'tokenized_input' to tokens using the BERT tokenizer\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "# Getting the word IDs for each token in the 'tokenized_input'\n",
        "word_ids = tokenized_input.word_ids()\n",
        "print(word_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Et6YCRk_gR",
        "outputId": "53c2d63f-f019-4ac9-c9f7-7c15bd24be38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the tokenized_input\n",
        "tokenized_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_w-s-KEePvY",
        "outputId": "44f029c2-75c2-467c-a52f-483753056554"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the token IDs in the 'input_ids' field of the 'tokenized_input' to tokens using the BERT tokenizer\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csm6xbMAhNda",
        "outputId": "67c06de1-fd6a-4ecc-c441-d48ebd4680dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'eu',\n",
              " 'rejects',\n",
              " 'german',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'british',\n",
              " 'lamb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the lengths of tokens and NER tags for the first example in the training set\n",
        "len(tokens), len(conllpp[\"train\"][0][\"ner_tags\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqOBM1PXh4mo",
        "outputId": "7670c82e-88e9-4eb2-b890-8846925dfad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to tokenize input examples and align the labels with the tokens.\n",
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "    # Tokenize the input examples\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over each example\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        # Retrieve the word IDs for the tokens in the current example\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        # Initialize variables\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        # Iterate over each token's word ID and corresponding label\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # Handle special tokens by setting the label to -100\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # If the word index is different from the previous one,\n",
        "                # it's a new word, so assign the corresponding label\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # If the word index is the same as the previous one,\n",
        "                # it's a sub-word, so handle it based on the label_all_tokens flag\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        # Append the label IDs for the current example\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    # Add the labels to the tokenized inputs\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "eI9cch_0iz5z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing and display the fifth example from the training split of the 'conllpp' dataset.\n",
        "conllpp[\"train\"][4:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFNWvdRinfma",
        "outputId": "ba6497fb-f0f1-4cfb-a3cd-e1871933d01d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': ['4'],\n",
              " 'tokens': [['Germany',\n",
              "   \"'s\",\n",
              "   'representative',\n",
              "   'to',\n",
              "   'the',\n",
              "   'European',\n",
              "   'Union',\n",
              "   \"'s\",\n",
              "   'veterinary',\n",
              "   'committee',\n",
              "   'Werner',\n",
              "   'Zwingmann',\n",
              "   'said',\n",
              "   'on',\n",
              "   'Wednesday',\n",
              "   'consumers',\n",
              "   'should',\n",
              "   'buy',\n",
              "   'sheepmeat',\n",
              "   'from',\n",
              "   'countries',\n",
              "   'other',\n",
              "   'than',\n",
              "   'Britain',\n",
              "   'until',\n",
              "   'the',\n",
              "   'scientific',\n",
              "   'advice',\n",
              "   'was',\n",
              "   'clearer',\n",
              "   '.']],\n",
              " 'pos_tags': [[22,\n",
              "   27,\n",
              "   21,\n",
              "   35,\n",
              "   12,\n",
              "   22,\n",
              "   22,\n",
              "   27,\n",
              "   16,\n",
              "   21,\n",
              "   22,\n",
              "   22,\n",
              "   38,\n",
              "   15,\n",
              "   22,\n",
              "   24,\n",
              "   20,\n",
              "   37,\n",
              "   21,\n",
              "   15,\n",
              "   24,\n",
              "   16,\n",
              "   15,\n",
              "   22,\n",
              "   15,\n",
              "   12,\n",
              "   16,\n",
              "   21,\n",
              "   38,\n",
              "   17,\n",
              "   7]],\n",
              " 'chunk_tags': [[11,\n",
              "   11,\n",
              "   12,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   21,\n",
              "   22,\n",
              "   11,\n",
              "   13,\n",
              "   11,\n",
              "   1,\n",
              "   13,\n",
              "   11,\n",
              "   17,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   1,\n",
              "   0]],\n",
              " 'ner_tags': [[5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   3,\n",
              "   4,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   2,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenize_and_align_labels(conllpp[\"train\"][4:5])\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgv1OXvhlEDA",
        "outputId": "93df0365-bea0-4b8a-ace0-d5c427f28193"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now applying tokenize_and_align_labels on the entire data\n",
        "tokenized_data = conllpp.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "id": "cowYSlJxqpMT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying tokenized_data\n",
        "tokenized_data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq7wcSBfr63v",
        "outputId": "b753f4d4-ca5b-4fc0-c001-604151b44039"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
              " 'input_ids': [101,\n",
              "  7327,\n",
              "  19164,\n",
              "  2446,\n",
              "  2655,\n",
              "  2000,\n",
              "  17757,\n",
              "  2329,\n",
              "  12559,\n",
              "  1012,\n",
              "  102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a pre-trained BERT model for token classification\n",
        "# The model is initialized with weights from the 'bert-base-uncased' checkpoint\n",
        "# 'num_labels=9' specifies the number of output labels for token classification\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8pqb3mJsyje",
        "outputId": "a6c60b1c-269a-4879-cfc0-772a18676337"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing necessary packages\n",
        "!pip install accelerate -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd7jJ73FZoug",
        "outputId": "4954237f-51f9-40ed-a680-321828f26882"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing necessary packages\n",
        "!pip install transformers[torch]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtxb4l4HaG1c",
        "outputId": "df43516f-9ef5-4fc2-9c04-e777b7fd077c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining  training args\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "\"NER\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=5,\n",
        "weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "x4k4mzl9t1wM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Datacollator necessary in preparing data for training BERT model\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "BHOgGnWPzjS9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Seqeval metric from the datasets library\n",
        "metric = datasets.load_metric(\"seqeval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f8bc775a6c1f4c6d8b1618d58b7b154b",
            "570320c4f336401fa438467fa8e81797",
            "d3ca2f6697de470b83a071df0e959277",
            "2a4294d57c18425c98449565f887062f",
            "54219af59cea4e428fc3d418319e8dfd",
            "a1780a0be35b4bcdbbaa389223cb23cc",
            "276fe006f6de46a9802411340180b804",
            "0b883cc9a6134feb8e3ef42c5d323ed5",
            "b418204c51e646b3b4d769fa127f34ed",
            "bea017bd4f3a400f939a4145b505885d",
            "55d273f081d64087850099f210abd1ff"
          ]
        },
        "id": "Ye2ZKzLB2uqZ",
        "outputId": "91cf787b-ae89-4755-d695-c4c024591849"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-9812856258f1>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8bc775a6c1f4c6d8b1618d58b7b154b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract label list from the dataset\n",
        "label_list = conllpp[\"train\"].features[\"ner_tags\"].feature.names\n",
        "\n",
        "# Print the label list\n",
        "print(label_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPL5gzULa8AV",
        "outputId": "d1575cf1-90c4-42e2-cb9c-0e61166f781d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack the evaluation predictions into predicted logits and true labels\n",
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we donâ€™t need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }\n"
      ],
      "metadata": {
        "id": "0WZSVKfq3bev"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The fine-tuned model to be trained\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "QNHpFZgY4E_B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating the training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "pFRvKXth56-4",
        "outputId": "3817aeb0-a567-4a7c-9733-a3c59e8861bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4390/4390 14:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.221300</td>\n",
              "      <td>0.057230</td>\n",
              "      <td>0.931615</td>\n",
              "      <td>0.934221</td>\n",
              "      <td>0.932916</td>\n",
              "      <td>0.984320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045200</td>\n",
              "      <td>0.055958</td>\n",
              "      <td>0.937979</td>\n",
              "      <td>0.944065</td>\n",
              "      <td>0.941012</td>\n",
              "      <td>0.985718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025100</td>\n",
              "      <td>0.056653</td>\n",
              "      <td>0.940680</td>\n",
              "      <td>0.947310</td>\n",
              "      <td>0.943983</td>\n",
              "      <td>0.986576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.061288</td>\n",
              "      <td>0.936977</td>\n",
              "      <td>0.951337</td>\n",
              "      <td>0.944102</td>\n",
              "      <td>0.986433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>0.063860</td>\n",
              "      <td>0.939954</td>\n",
              "      <td>0.950889</td>\n",
              "      <td>0.945390</td>\n",
              "      <td>0.986624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4390, training_loss=0.050713736647082355, metrics={'train_runtime': 877.8515, 'train_samples_per_second': 79.974, 'train_steps_per_second': 5.001, 'total_flos': 1702317283240608.0, 'train_loss': 0.050713736647082355, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "model.save_pretrained(\"NER_MODEL\")"
      ],
      "metadata": {
        "id": "qvf0jkhPeLb8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8GFLPcqkmzc",
        "outputId": "ede22627-c759-4ea1-8ce9-1c1733389d9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create id to label mapping\n",
        "id2label = {\n",
        "    str(idx): label for idx, label in enumerate(label_list)\n",
        "}\n",
        "\n",
        "# Create label to id mapping\n",
        "label2id = {\n",
        "    label: str(idx) for idx, label in enumerate(label_list)\n",
        "}\n"
      ],
      "metadata": {
        "id": "uIrfMingktRc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying id2label and label2id\n",
        "id2label, label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvBIhiaulB_C",
        "outputId": "03362a24-349e-406d-d733-d073cc964568"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'0': 'O',\n",
              "  '1': 'B-PER',\n",
              "  '2': 'I-PER',\n",
              "  '3': 'B-ORG',\n",
              "  '4': 'I-ORG',\n",
              "  '5': 'B-LOC',\n",
              "  '6': 'I-LOC',\n",
              "  '7': 'B-MISC',\n",
              "  '8': 'I-MISC'},\n",
              " {'O': '0',\n",
              "  'B-PER': '1',\n",
              "  'I-PER': '2',\n",
              "  'B-ORG': '3',\n",
              "  'I-ORG': '4',\n",
              "  'B-LOC': '5',\n",
              "  'I-LOC': '6',\n",
              "  'B-MISC': '7',\n",
              "  'I-MISC': '8'})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and Prediction\n",
        "import json\n",
        "\n",
        "# Load existing configuration from file\n",
        "with open(\"NER_MODEL/config.json\", \"r\") as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "# Update configuration with id to label and label to id mappings\n",
        "config[\"id2label\"] = id2label\n",
        "config[\"label2id\"] = label2id\n",
        "\n",
        "# Write updated configuration back to file\n",
        "with open(\"NER_MODEL/config.json\", \"w\") as config_file:\n",
        "    json.dump(config, config_file)\n"
      ],
      "metadata": {
        "id": "puPcFDIclRjS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned token classification model from the \"NER_MODEL\"\n",
        "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"NER_MODEL\")\n"
      ],
      "metadata": {
        "id": "k3pJgOPomSig"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline for Named Entity Recognition (NER)\n",
        "ner_pipeline = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n",
        "\n",
        "# Test sentence\n",
        "test_sentence = \"Steve Jobs is the founder of Apple which is headquatered in Mountain view California and known for its innovative technology.\"\n",
        "\n",
        "# Perform NER on the test sentence\n",
        "ner_results = ner_pipeline(test_sentence)\n",
        "\n",
        "print(ner_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VhOjjlMmziv",
        "outputId": "d973634d-202e-4286-8e18-2eb2c7b527b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-PER', 'score': 0.99846554, 'index': 1, 'word': 'steve', 'start': 0, 'end': 5}, {'entity': 'I-PER', 'score': 0.9983109, 'index': 2, 'word': 'jobs', 'start': 6, 'end': 10}, {'entity': 'B-ORG', 'score': 0.9933189, 'index': 7, 'word': 'apple', 'start': 29, 'end': 34}, {'entity': 'B-LOC', 'score': 0.9975793, 'index': 14, 'word': 'mountain', 'start': 60, 'end': 68}, {'entity': 'I-LOC', 'score': 0.9520391, 'index': 15, 'word': 'view', 'start': 69, 'end': 73}, {'entity': 'I-LOC', 'score': 0.9785978, 'index': 16, 'word': 'california', 'start': 74, 'end': 84}]\n"
          ]
        }
      ]
    }
  ]
}